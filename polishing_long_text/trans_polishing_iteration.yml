app:
  description: ''
  icon: ðŸ¤–
  icon_background: '#FFEAD5'
  mode: workflow
  name: trans_polishing_iteration
  use_icon_as_answer_icon: false
kind: app
version: 0.1.3
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        sourceType: document-extractor
        targetType: code
      id: 1731398164005-source-1731398210973-target
      source: '1731398164005'
      sourceHandle: source
      target: '1731398210973'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: iteration
      id: 1731398210973-source-1731923324290-target
      source: '1731398210973'
      sourceHandle: source
      target: '1731923324290'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: true
        iteration_id: '1731923324290'
        sourceType: iteration-start
        targetType: llm
      id: 1731923324290start-source-1731923549594-target
      source: 1731923324290start
      sourceHandle: source
      target: '1731923549594'
      targetHandle: target
      type: custom
      zIndex: 1002
    - data:
        isInIteration: false
        sourceType: iteration
        targetType: template-transform
      id: 1731923324290-source-1731924271905-target
      source: '1731923324290'
      sourceHandle: source
      target: '1731924271905'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: template-transform
        targetType: end
      id: 1731924271905-source-1731924342417-target
      source: '1731924271905'
      sourceHandle: source
      target: '1731924342417'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: start
        targetType: document-extractor
      id: 1731397847895-source-1731398164005-target
      source: '1731397847895'
      sourceHandle: source
      target: '1731398164005'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: Start
        type: start
        variables:
        - allowed_file_extensions: []
          allowed_file_types:
          - image
          - document
          allowed_file_upload_methods:
          - local_file
          - remote_url
          label: upload_file
          max_length: 48
          options: []
          required: true
          type: file
          variable: upload_file
      height: 90
      id: '1731397847895'
      position:
        x: 63.2406929289167
        y: 532.2723189281774
      positionAbsolute:
        x: 63.2406929289167
        y: 532.2723189281774
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        is_array_file: false
        selected: false
        title: Doc Extractor
        type: document-extractor
        variable_selector:
        - '1731397847895'
        - upload_file
      height: 94
      id: '1731398164005'
      position:
        x: 384
        y: 282
      positionAbsolute:
        x: 384
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import re\nimport sys\n\ndef count_tokens(text: str) -> int:\n    \"\
          \"\"\n    Count tokens for both English and Chinese text.\n    - For English:\
          \ splits by whitespace\n    - For Chinese: counts each character as a token\n\
          \    \"\"\"\n    has_chinese = bool(re.search(r'[\\u4e00-\\u9fff]', text))\n\
          \    \n    if has_chinese:\n        cleaned_text = re.sub(r'\\s+', '', text)\n\
          \        return len(cleaned_text)\n    else:\n        return len(text.split())\n\
          \ndef split_by_length(text: str, max_tokens: int, is_chinese: bool) -> list:\n\
          \    \"\"\"Split text by length when no punctuation is found\"\"\"\n   \
          \ chunks = []\n    \n    if is_chinese:\n        chars = list(text.strip())\n\
          \        current_chunk = []\n        current_count = 0\n        \n     \
          \   for char in chars:\n            if current_count >= max_tokens:\n  \
          \              chunks.append(''.join(current_chunk))\n                current_chunk\
          \ = []\n                current_count = 0\n            current_chunk.append(char)\n\
          \            current_count += 1\n            \n        if current_chunk:\n\
          \            chunks.append(''.join(current_chunk))\n    else:\n        words\
          \ = text.strip().split()\n        current_chunk = []\n        current_count\
          \ = 0\n        \n        for word in words:\n            if current_count\
          \ >= max_tokens:\n                chunks.append(' '.join(current_chunk))\n\
          \                current_chunk = []\n                current_count = 0\n\
          \            current_chunk.append(word)\n            current_count += 1\n\
          \            \n        if current_chunk:\n            chunks.append(' '.join(current_chunk))\n\
          \    \n    return chunks\n\ndef main(input_text: str) -> dict:\n    # Initialize\
          \ parameters\n    token_limit = 1024\n    chunks = []\n    current_chunk\
          \ = []\n    current_token_count = 0\n    \n    # Check if text contains\
          \ Chinese characters\n    has_chinese = bool(re.search(r'[\\u4e00-\\u9fff]',\
          \ input_text))\n    \n    # Split text based on language\n    if has_chinese:\n\
          \        segments = re.split(r'([ã€‚ï¼ï¼Ÿ])', input_text)\n        if len(segments)\
          \ > 1:\n            segments = [''.join(i) for i in zip(segments[0::2],\
          \ segments[1::2] + [''])]\n        else:\n            return {\"chunks\"\
          : split_by_length(input_text, token_limit, has_chinese)}\n    else:\n  \
          \      segments = re.split(r'([.!?])', input_text)\n        if len(segments)\
          \ > 1:\n            segments = [''.join(i) for i in zip(segments[0::2],\
          \ segments[1::2] + [''])]\n        else:\n            return {\"chunks\"\
          : split_by_length(input_text, token_limit, has_chinese)}\n    \n    for\
          \ segment in segments:\n        if not segment.strip():\n            continue\n\
          \            \n        segment = segment.strip()\n        segment_tokens\
          \ = count_tokens(segment)\n        \n        # If segment alone exceeds\
          \ max tokens, split it\n        if segment_tokens > token_limit:\n     \
          \       if current_chunk:\n                chunk_text = (''.join(current_chunk)\
          \ if has_chinese else ' '.join(current_chunk))\n                chunks.append(chunk_text)\n\
          \                current_chunk = []\n                current_token_count\
          \ = 0\n            \n            sub_chunks = split_by_length(segment, token_limit,\
          \ has_chinese)\n            chunks.extend(sub_chunks)\n            continue\n\
          \        \n        # If adding this segment would exceed token limit and\
          \ we have content,\n        # store the current chunk and start a new one\n\
          \        if current_token_count + segment_tokens > token_limit and current_chunk:\n\
          \            chunk_text = (''.join(current_chunk) if has_chinese else '\
          \ '.join(current_chunk))\n            chunks.append(chunk_text)\n      \
          \      current_chunk = []\n            current_token_count = 0\n       \
          \     \n        # Add segment to current chunk\n        current_chunk.append(segment)\n\
          \        current_token_count += segment_tokens\n    \n    # Add final chunk\
          \ if exists\n    if current_chunk:\n        chunk_text = (''.join(current_chunk)\
          \ if has_chinese else ' '.join(current_chunk))\n        chunks.append(chunk_text)\n\
          \    \n    return {\n        \"chunks\": chunks\n    }\n\n"
        code_language: python3
        desc: ''
        outputs:
          chunks:
            children: null
            type: array[string]
        selected: false
        title: Code
        type: code
        variables:
        - value_selector:
          - '1731398164005'
          - text
          variable: input_text
      height: 54
      id: '1731398210973'
      position:
        x: 690
        y: 282
      positionAbsolute:
        x: 690
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        error_handle_mode: terminated
        height: 186
        is_parallel: false
        iterator_selector:
        - '1731398210973'
        - chunks
        output_selector:
        - '1731923549594'
        - text
        output_type: array[string]
        parallel_nums: 10
        selected: false
        start_node_id: 1731923324290start
        title: Iteration
        type: iteration
        width: 388
      height: 186
      id: '1731923324290'
      position:
        x: 994
        y: 282
      positionAbsolute:
        x: 994
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 388
      zIndex: 1
    - data:
        desc: ''
        isInIteration: true
        selected: false
        title: ''
        type: iteration-start
      draggable: false
      height: 48
      id: 1731923324290start
      parentId: '1731923324290'
      position:
        x: 24
        y: 68
      positionAbsolute:
        x: 1018
        y: 350
      selectable: false
      sourcePosition: right
      targetPosition: left
      type: custom-iteration-start
      width: 44
      zIndex: 1002
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        isInIteration: true
        iteration_id: '1731923324290'
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o-mini
          provider: openai
        prompt_template:
        - id: 7d36103d-9825-4b8c-b440-a2fb13836df7
          role: system
          text: "You are an expert editor and proofreader tasked with polishing and\
            \ improving a given document. Your goal is to enhance the quality of the\
            \ writing while preserving its original content and language. \nHere is\
            \ the sentence you need to polish: {{#1731923324290.item#}}\nPlease follow\
            \ these steps to improve the document: \n1. Carefully inspect the entire\
            \ document. \n2. Identify and correct all spelling and grammatical errors.\
            \ \n3. Improve the writing quality sentence by sentence, making it smooth\
            \ and easy to understand. \n4. Add suitable punctuation to break up sentences\
            \ and improve readability. \n5. Ensure that the language of the document\
            \ remains unchanged. \n6. Do not delete any content from the original\
            \ document.\n"
        selected: false
        title: LLM 3
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1731923549594'
      parentId: '1731923324290'
      position:
        x: 128
        y: 68
      positionAbsolute:
        x: 1122
        y: 350
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1002
    - data:
        desc: ''
        selected: false
        template: '{{ processed_text | join('' '') }}'
        title: Template
        type: template-transform
        variables:
        - value_selector:
          - '1731923324290'
          - output
          variable: processed_text
      height: 54
      id: '1731924271905'
      position:
        x: 1442
        y: 282
      positionAbsolute:
        x: 1442
        y: 282
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        outputs: []
        selected: false
        title: End
        type: end
      height: 54
      id: '1731924342417'
      position:
        x: 1746
        y: 282
      positionAbsolute:
        x: 1746
        y: 282
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -1163.9068324934524
      y: 232.9372530832565
      zoom: 0.8950250709279725
